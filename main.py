from fastapi import FastAPI
from pydantic import BaseModel
import requests
import google.generativeai as genai
from langchain.memory import ConversationBufferMemory

# Ø¥Ø¹Ø¯Ø§Ø¯ API
app = FastAPI()

# Ø¥Ø¹Ø¯Ø§Ø¯ Gemini
genai.configure(api_key=GOOGLE_API_KEY)
model = genai.GenerativeModel("gemini-2.5-flash")

# Ø§Ù„Ø°Ø§ÙƒØ±Ø©
user_memories = {}
user_last_questions = {}

def get_user_memory(user_id: str):
    if user_id not in user_memories:
        user_memories[user_id] = ConversationBufferMemory(return_messages=True)
    return user_memories[user_id]

# ØªÙˆÙ„ÙŠØ¯ Ø±Ø¯ Ù…Ø¹ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªØ§Ø±ÙŠØ®
def generate_with_history(memory, prompt, limit=3):
    chat_history = memory.load_memory_variables({}).get("history", [])
    recent_history = chat_history[-limit:]
    chat_text = "\n".join([m.content if hasattr(m, "content") else str(m) for m in recent_history]) + "\n" + prompt
    return model.generate_content(chat_text).text.strip()

# Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø¥Ø¬Ø§Ø¨Ø© ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙØ©
def is_unknown_answer(text):
    unknown_phrases = [
        "Ù„Ø§ Ø£Ø¹Ø±Ù", "Ù„Ø§ Ø§Ø¯Ø±ÙŠ", "Ù…Ø§ Ø§Ø¹Ø±Ù", "Ù…Ø´ Ø¹Ø§Ø±Ù", "Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©", "Ù…Ø§ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©", "Ø¥ÙŠÙ‡ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©", "Ù…Ø¹Ø±ÙØ´", "Ù…Ù…ÙƒÙ† Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©", "Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¥ÙŠÙ‡"
    ]
    return any(phrase in text.lower() for phrase in unknown_phrases)

# Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
class ChatRequest(BaseModel):
    user_id: str
    message: str

@app.post("/chat")
def chat(req: ChatRequest):
    user_id = req.user_id
    user_input = req.message.strip()
    memory = get_user_memory(user_id)

    # Ø§Ù„ØªØ­ÙŠØ©
    greetings = ["Ù…Ø³Ø§Ø¡ Ø§Ù„Ø®ÙŠØ±", "ØµØ¨Ø§Ø­ Ø§Ù„Ø®ÙŠØ±", "Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ…", "Ø£Ù‡Ù„Ø§", "Ø£Ù‡Ù„Ø§Ù‹", "Ù‡Ø§ÙŠ", "Ù‡Ù„Ø§", "Ø¥Ø²ÙŠÙƒ", "Ù…Ø±Ø­Ø¨Ø§", "hello", "hi"]
    if any(greet in user_input.lower() for greet in greetings):
        reply = "ğŸ‘‹ Ø£Ù‡Ù„Ø§Ù‹ ÙˆØ³Ù‡Ù„Ø§Ù‹! ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø§Ù„ÙŠÙˆÙ…ØŸ"
        memory.chat_memory.add_user_message(user_input)
        memory.chat_memory.add_ai_message(reply)
        return {"response": reply}

    # Ø§Ù„Ø±Ø¯ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±
    if "Ø¹Ù†ÙˆØ§Ù†" in user_input:
        prompt = f"""Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙƒØªØ¨ ÙÙƒØ±Ø©: "{user_input}"\nØ§Ù‚ØªØ±Ø­ Ù„Ù‡ Ø¹Ù†ÙˆØ§Ù†Ù‹Ø§ Ø¬Ø°Ø§Ø¨Ù‹Ø§ Ù„Ù…Ù‚Ø§Ù„ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©."""
        reply = model.generate_content(prompt).text.strip()
        memory.chat_memory.add_user_message(user_input)
        memory.chat_memory.add_ai_message(reply)
        return {"response": reply}

    if "ÙÙƒØ±Ø©" in user_input and "Ø§ÙƒØªØ¨" in user_input:
        prompt = f"""Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙƒØªØ¨ ÙÙƒØ±Ø©: "{user_input}"\nØ§ÙƒØªØ¨ Ù„Ù‡ ÙÙ‚Ø±Ø© Ø¨Ù„ØºØ© ÙØµØ­Ù‰ ÙˆØ£Ø³Ù„ÙˆØ¨ Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠ."""
        reply = model.generate_content(prompt).text.strip()
        memory.chat_memory.add_user_message(user_input)
        memory.chat_memory.add_ai_message(reply)
        return {"response": reply}

    if "Ø£Ø¹Ø±Ø¨" in user_input:
        prompt = f"""Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø·Ù„Ø¨ Ø¥Ø¹Ø±Ø§Ø¨ Ø§Ù„Ø¬Ù…Ù„Ø©:\n"{user_input}"\nØ£Ø¹Ø±Ø¨Ù‡Ø§ ØªÙØµÙŠÙ„ÙŠÙ‹Ø§ ÙˆÙØ³Ù‘Ø± Ø¨Ù„ØºØ© Ø¨Ø³ÙŠØ·Ø©."""
        reply = model.generate_content(prompt).text.strip()
        memory.chat_memory.add_user_message(user_input)
        memory.chat_memory.add_ai_message(reply)
        return {"response": reply}

    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ÙŠØ©
    intent_prompt = f"""
    Ø­Ù„Ù„ Ø§Ù„Ø¬Ù…Ù„Ø© Ø§Ù„ØªØ§Ù„ÙŠØ© ÙˆØ­Ø¯Ø¯:
    - Ù†ÙˆØ¹ Ø§Ù„Ø·Ù„Ø¨: Ù…Ø¹Ù†Ù‰ / Ø¬Ù…Ø¹ / ØªØ¶Ø§Ø¯ / Ø´Ø±Ø­ / ØµØ±Ù / ÙƒØªØ§Ø¨Ø© ÙÙ‚Ø±Ø© / Ø³Ø¤Ø§Ù„ ØªØ¹Ù„ÙŠÙ…ÙŠ / ØªÙ‚ÙŠÙŠÙ… Ø¥Ø¬Ø§Ø¨Ø©.
    - Ø§Ù„ÙƒÙ„Ù…Ø© Ø£Ùˆ Ø§Ù„Ø¯Ø±Ø³ Ø£Ùˆ Ø§Ù„Ù…Ø­ØªÙˆÙ‰.
    Ø§Ù„Ø¬Ù…Ù„Ø©:
    "{user_input}"
    Ø£Ø¬Ø¨ ÙÙ‚Ø· Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø´ÙƒÙ„:
    intent: ...
    word: ...
    """
    try:
        analysis = generate_with_history(memory, intent_prompt)
        intent = analysis.split("intent:")[1].split("\n")[0].strip()
        word = analysis.split("word:")[1].strip()
    except:
        intent = ""
        word = ""

    # âœ… Ø¥Ø°Ø§ Ø§Ù„Ø¬Ù…Ù„Ø© ÙÙŠÙ‡Ø§ "Ù„Ø§ Ø£Ø¹Ø±Ù" Ø£Ùˆ Ù…Ø§ Ø´Ø§Ø¨Ù‡ â†’ Ù†Ø±Ø³Ù„ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ÙŠØ©
    if is_unknown_answer(user_input):
        if user_id in user_last_questions:
            lesson = user_last_questions[user_id]["lesson"]
            question = user_last_questions[user_id]["question"]
            answer_prompt = f"""Ø§ÙƒØªØ¨ Ø¥Ø¬Ø§Ø¨Ø© Ù†Ù…ÙˆØ°Ø¬ÙŠØ© Ù„Ù‡Ø°Ø§ Ø§Ù„Ø³Ø¤Ø§Ù„ Ù…Ù† Ø¯Ø±Ø³ {lesson}:\n{question}"""
            reply = model.generate_content(answer_prompt).text.strip()
        else:
            reply = "âŒ Ù„Ù… ÙŠØªÙ… ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø°ÙŠ ØªØ±ÙŠØ¯ Ø¥Ø¬Ø§Ø¨ØªÙ‡. Ø§Ø·Ù„Ø¨ Ø³Ø¤Ø§Ù„Ù‹Ø§ Ø£ÙˆÙ„Ø§Ù‹."
        memory.chat_memory.add_user_message(user_input)
        memory.chat_memory.add_ai_message(reply)
        return {"response": reply}

    # âœ… Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù„Ø¯ÙŠÙ‡ Ø³Ø¤Ø§Ù„ Ù…Ø­ÙÙˆØ¸ ÙˆÙƒØ§Ù† intent ØºÙŠØ± Ù…Ø­Ø¯Ø¯ â†’ Ù†Ø¹ØªØ¨Ø±Ù‡Ø§ Ø¥Ø¬Ø§Ø¨Ø©
    if user_id in user_last_questions:
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ù„ÙŠØ³ Ø·Ù„Ø¨ Ø¬Ø¯ÙŠØ¯ Ù„Ù„Ù…Ø¹Ø§Ù†ÙŠ Ø£Ùˆ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©
        if intent not in ["Ù…Ø¹Ù†Ù‰", "Ø¬Ù…Ø¹", "ØªØ¶Ø§Ø¯", "Ø´Ø±Ø­", "ØµØ±Ù", "Ø³Ø¤Ø§Ù„ ØªØ¹Ù„ÙŠÙ…ÙŠ", "ÙƒØªØ§Ø¨Ø© ÙÙ‚Ø±Ø©"]:
            # Ø§Ù„ØªØ£ÙƒØ¯ Ø£Ù† Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ù„ÙŠØ³ ØªØ­ÙŠØ© Ø£Ùˆ Ø·Ù„Ø¨ Ù…Ø³Ø§Ø¹Ø¯Ø© Ø¹Ø§Ù…
            general_requests = ["Ù…Ø³Ø§Ø¹Ø¯Ø©", "help", "Ø§ÙŠÙ‡", "Ø¥ÙŠÙ‡", "Ø´Ùˆ", "ÙˆØ´", "ÙƒÙŠÙ"]
            if not any(req in user_input.lower() for req in general_requests):
                intent = "ØªÙ‚ÙŠÙŠÙ… Ø¥Ø¬Ø§Ø¨Ø©"
                word = user_input

    # ØªÙ†ÙÙŠØ° Ø­Ø³Ø¨ Ø§Ù„Ù†ÙŠØ©
    if intent in ["ÙƒØªØ§Ø¨Ø© ÙÙ‚Ø±Ø©", "Ø´Ø±Ø­"]:
        prompt = f"Ø§ÙƒØªØ¨ ÙÙ‚Ø±Ø© Ø¨Ø³ÙŠØ·Ø© Ø­ÙˆÙ„: {word}"
        reply = model.generate_content(prompt).text.strip()

    elif intent == "ØµØ±Ù":
        try:
            res = requests.post("https://malak-hossam-morpology.hf.space/morphology", json={"text": word})
            if res.status_code == 200:
                result_list = res.json().get("result", [])
                if result_list and isinstance(result_list, list):
                    output = result_list[0]
                    reply = "\n".join([f"{key}: {val}" for key, val in output.items()])
                else:
                    reply = f"âŒ Ù„Ù… Ø£Ø¬Ø¯ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµØ±ÙÙŠ Ù„Ù„ÙƒÙ„Ù…Ø©: {word}."
            else:
                reply = f"âŒ Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø®Ø¯Ù…Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµØ±ÙÙŠ."
        except:
            reply = f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø¬Ù„Ø¨ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµØ±ÙÙŠ Ù„Ù„ÙƒÙ„Ù…Ø©: {word}."

    elif intent in ["Ù…Ø¹Ù†Ù‰", "Ø¬Ù…Ø¹", "ØªØ¶Ø§Ø¯"]:
        try:
            type_map = {"Ù…Ø¹Ù†Ù‰": "synonyms", "ØªØ¶Ø§Ø¯": "antonyms", "Ø¬Ù…Ø¹": "plural"}
            res = requests.post("https://malak-hossam-word-meaning.hf.space/analyze/", json={"word": word, "type": type_map[intent]})
            meaning = res.json().get("result", "")
            reply = meaning if meaning else f"âŒ Ù„Ù… Ø£Ø¬Ø¯ {intent} Ù„Ù„ÙƒÙ„Ù…Ø©: {word}."
        except:
            reply = f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø¬Ù„Ø¨ {intent} Ù„Ù„ÙƒÙ„Ù…Ø©: {word}."

    elif intent == "Ø³Ø¤Ø§Ù„ ØªØ¹Ù„ÙŠÙ…ÙŠ":
        difficulty = "ØµØ¹Ø¨" if "ØµØ¹Ø¨" in user_input else "Ø³Ù‡Ù„" if "Ø³Ù‡Ù„" in user_input else "Ø¹Ø§Ø¯ÙŠ"
        prompt = f"""
Ø§ÙƒØªØ¨ ØªÙ…Ø±ÙŠÙ†Ù‹Ø§ Ù†Ø­ÙˆÙŠÙ‹Ø§ Ø¹Ù„Ù‰ Ø¯Ø±Ø³ "{word}" Ø¨Ù…Ø³ØªÙˆÙ‰ {difficulty}.
ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ­ØªÙˆÙŠ Ø§Ù„ØªÙ…Ø±ÙŠÙ† Ø¹Ù„Ù‰:
- Ø¹Ù†ÙˆØ§Ù† ÙˆØ§Ø¶Ø­
- ØµÙŠØºØ© Ø§Ù„Ø³Ø¤Ø§Ù„
- Ù…Ù† 2 Ø¥Ù„Ù‰ 3 Ø¬Ù…Ù„ Ù„Ù„Ø·Ø§Ù„Ø¨ Ù„ÙŠØ¹Ø±Ø¨Ù‡Ø§ Ø£Ùˆ ÙŠØ­Ø¯Ø¯ Ø¹Ù†Ø§ØµØ±Ù‡Ø§.
Ù„Ø§ ØªØ¶Ø¹ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©.
"""
        reply = model.generate_content(prompt).text.strip()
        user_last_questions[user_id] = {"lesson": word, "question": reply}

    elif intent == "ØªÙ‚ÙŠÙŠÙ… Ø¥Ø¬Ø§Ø¨Ø©":
        if user_id not in user_last_questions:
            reply = "âŒ Ù„Ù… ØªÙ‚Ù… Ø¨Ø·Ù„Ø¨ Ø³Ø¤Ø§Ù„ Ø¨Ø¹Ø¯. Ø§Ø·Ù„Ø¨ Ø³Ø¤Ø§Ù„ Ø£ÙˆÙ„Ù‹Ø§ Ù…Ø«Ù„Ø§Ù‹: Ø§Ø¯ÙŠÙ†ÙŠ Ø³Ø¤Ø§Ù„ Ø¹Ù„Ù‰ Ø¯Ø±Ø³ ÙƒØ°Ø§."
        else:
            question_data = user_last_questions[user_id]
            question = question_data["question"]
            lesson = question_data["lesson"]
            answer = word
            eval_prompt = f"""
Ø£Ù†Øª Ù…Ø¯Ù‚Ù‚ Ù†Ø­ÙˆÙŠ Ù…Ø­ØªØ±Ù. Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ù…Ù†Ùƒ ØªÙ‚ÙŠÙŠÙ… Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ø·Ø§Ù„Ø¨ Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„ØªØ§Ù„ÙŠ.
ğŸ”¹ Ø§Ù„Ø³Ø¤Ø§Ù„:
{question}
ğŸ”¹ Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ø·Ø§Ù„Ø¨:
{answer}
ğŸ“Œ Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª:
- Ø§Ø¨Ø¯Ø£ Ø¨Ù€ "Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©: ØµØ­ÙŠØ­Ø©." Ø£Ùˆ "Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©: Ø®Ø§Ø·Ø¦Ø©."
- Ø«Ù… ØªØ¹Ù„ÙŠÙ„ Ù…Ø®ØªØµØ±.
- Ù„Ø§ ØªØ³ØªØ®Ø¯Ù… Ù†Ø¨Ø±Ø© Ø³Ù„Ø¨ÙŠØ©.
- Ù„Ø§ ØªÙƒØ±Ø± Ù†ÙØ³ Ø§Ù„Ø³Ø¤Ø§Ù„.
Ø§Ù„Ø¢Ù† Ù‚ÙŠÙ‘Ù…:
"""
            reply = model.generate_content(eval_prompt).text.strip()

    else:
        reply = "âŒ Ù„Ù… Ø£ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ù†ÙˆØ¹ Ø§Ù„Ø³Ø¤Ø§Ù„. Ø¬Ø±Ø¨ Ø¨ØµÙŠØºØ© Ø£Ø®Ø±Ù‰."

    memory.chat_memory.add_user_message(user_input)
    memory.chat_memory.add_ai_message(reply)

    return {"response": reply}
